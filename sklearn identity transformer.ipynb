{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn identity transformer\n",
    "This is for my blogpost, which you can find [here](), about writing an identity transformer for sklearn's Pipeline and FeatureUnion. Basically, this allows for concatenating a vector to (a transformed version of) itself. That way, the same transformation doesn't have to be carried out twice.\n",
    "\n",
    "## Data loading\n",
    "Just the usual data-loading that I got from the blogpost at [Ultraviolet Analytics](http://www.ultravioletanalytics.com/2014/10/30/kaggle-titanic-competition-part-i-intro/). Basically loads the dataset into the `df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# Read in the training and testing data into Pandas.DataFrame objects\n",
    "# This assumes files are in the current directory\n",
    "input_df = pd.read_csv('train.csv', header=0)\n",
    "submit_df  = pd.read_csv('test.csv',  header=0)\n",
    " \n",
    "# Merge the two DataFrames into one\n",
    "df = pd.concat([input_df, submit_df])\n",
    "\n",
    "# Re-number the combined data set so there aren't duplicate indexes\n",
    "df.reset_index(inplace=True)\n",
    " \n",
    "# Reset_index() generates a new column that we don't want\n",
    "df.drop('index', axis=1, inplace=True)\n",
    " \n",
    "# The remaining columns need to be reindexed so we can access the first column at '0' instead of '1'\n",
    "df = df.reindex_axis(input_df.columns, axis=1)\n",
    " \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer classes\n",
    "Here are the three classes that we will be using as transformers for the `Cabin` column:\n",
    "* __Imputer transformer:__ This imputes the missing values in the Cabin column, replacing them with \"U0\"\n",
    "* __Factorizer transformer:__ This factorizes the different levels into n-1 classes (n-1 because the factorising starts at 0)\n",
    "* __Identity transformer:__ The identity transformation that will allow us to concatenate a vector to (a transformation of) itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CabinImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        # No need to fit, so simply return dataframe\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_array, y=None):\n",
    "        result = pd.DataFrame(input_array).fillna('U0')\n",
    "        return result\n",
    "    \n",
    "class CabinLetterFactorized(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, input_array, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_array, y=None):\n",
    "        single_cabin_letter = input_array[0].map( lambda c : c[0] )\n",
    "        result = pd.factorize(single_cabin_letter)[0]\n",
    "        return one_to_two(result)\n",
    "    \n",
    "class IdentityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, input_array, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_array, y=None):\n",
    "        return input_array*1\n",
    "    \n",
    "# Helper function, not really relevant to what I'm trying to show though\n",
    "# Converts a 1D numpy array to a 2D one that can be concatenated properly\n",
    "def one_to_two(data):\n",
    "    if isinstance(data, pd.Series):\n",
    "        return data.values.reshape(data.values.shape[0], -1)\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data.reshape(data.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `Pipeline` and `FeatureUnion`\n",
    "Now that we have our transformers defined above, it's time to put the pipeline to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['U0', 0],\n",
       "       ['C85', 1],\n",
       "       ['U0', 0],\n",
       "       ..., \n",
       "       ['U0', 0],\n",
       "       ['U0', 0],\n",
       "       ['U0', 0]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('imputer', CabinImputer()),\n",
    "    ('unioniser', FeatureUnion([\n",
    "        ('identity', IdentityTransformer()),\n",
    "        ('factorizer', CabinLetterFactorized()),\n",
    "    ]))\n",
    "])\n",
    "\n",
    "cabin_vector = one_to_two(df['Cabin'])\n",
    "pipe.fit_transform(cabin_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You can play around a bit to see what the effects are on configuration. Don't mind my pandas DataFrame shenanigans too much, I'm still getting used to switching between DataFrames and numpy arrays, and how to properly get that to work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
